{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mstats\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pieci\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# CARGAMOS EL DATASET YA LIMPIO PARA TRABAJAR CON LOS MODELOS\n",
    "\n",
    "df_LIMPIO=pd.read_csv('../data/df_LIMPIO_12_09.csv', index_col=0)\n",
    "# df_LIMPIO\n",
    "\n",
    "# REDUCIMOS LOS RANGOS ENTRE LOS QUE SE DIVIDIR√Å ENTRE 0 Y 4 PARA PROBAR CON DEEP LEARNING\n",
    "\n",
    "for i in range(len(df_LIMPIO['rangos_precios'])):\n",
    "    if df_LIMPIO['rangos_precios'].iloc[i] <= 50:\n",
    "        df_LIMPIO['rangos_precios'].iloc[i] = 0\n",
    "\n",
    "    elif 50 < df_LIMPIO['rangos_precios'].iloc[i] <= 100:\n",
    "        df_LIMPIO['rangos_precios'].iloc[i] = 1\n",
    "\n",
    "    elif 75 < df_LIMPIO['rangos_precios'].iloc[i] <= 150:\n",
    "        df_LIMPIO['rangos_precios'].iloc[i] = 2\n",
    "\n",
    "    else:\n",
    "        df_LIMPIO['rangos_precios'].iloc[i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7980\n",
       "1.0    6090\n",
       "3.0    2340\n",
       "2.0    1910\n",
       "Name: rangos_precios, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LIMPIO['rangos_precios'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_LIMPIO.drop(columns=[\n",
    "                        ## VARIABLES TARGET\n",
    "                        'rangos_precios',\n",
    "                        'price',\n",
    "\n",
    "                        'accommodates',\n",
    "                        # 'beds',\n",
    "\n",
    "                        'eur_distrito',\n",
    "                        # 'elevator',\n",
    "                        # 'latitude',\n",
    "                        # 'longitude',\n",
    "                        # 'amenities_len',\n",
    "                        # 'balcony',\n",
    "                        # 'pool',\n",
    "                        # 'wifi',\n",
    "                        'host_since_years',\n",
    "                        'single_level',\n",
    "                        'airport',\n",
    "                        'workspace',\n",
    "                        'breakfast',\n",
    "                        'nespresso',\n",
    "                        'dist_p_sol',\n",
    "                        'pet',\n",
    "                        'facturas_inc',\n",
    "                        'reviews_per_month',\n",
    "                        'review_scores_rating'\n",
    " ])\n",
    "\n",
    "        \n",
    "# y=df_LIMPIO['price_per_year']\n",
    "# y=df_LIMPIO['price_per_month']\n",
    "y=df_LIMPIO['rangos_precios']\n",
    "\n",
    "features = list(X)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X,\n",
    "                                                              y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full,\n",
    "                                                      y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.astype(\"float32\")/200\n",
    "# y_test = y_test.astype(\"float32\")/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10305, 16)\n",
      "(4580, 16)\n",
      "(10305,)\n",
      "(4580,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "capas = [\n",
    "    keras.layers.Flatten(input_shape= X_train.shape[1:]),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 4, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "323/323 [==============================] - 1s 1ms/step - loss: 1.0282 - accuracy: 0.5913 - val_loss: 0.9398 - val_accuracy: 0.6294\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.9270 - accuracy: 0.6340 - val_loss: 0.9101 - val_accuracy: 0.6358\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.9066 - accuracy: 0.6399 - val_loss: 0.8984 - val_accuracy: 0.6384\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8968 - accuracy: 0.6419 - val_loss: 0.8928 - val_accuracy: 0.6399\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8899 - accuracy: 0.6437 - val_loss: 0.8931 - val_accuracy: 0.6355\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8849 - accuracy: 0.6439 - val_loss: 0.8826 - val_accuracy: 0.6457\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8802 - accuracy: 0.6448 - val_loss: 0.8827 - val_accuracy: 0.6425\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8764 - accuracy: 0.6454 - val_loss: 0.8801 - val_accuracy: 0.6463\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8722 - accuracy: 0.6486 - val_loss: 0.8788 - val_accuracy: 0.6463\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8693 - accuracy: 0.6489 - val_loss: 0.8758 - val_accuracy: 0.6463\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8665 - accuracy: 0.6506 - val_loss: 0.8705 - val_accuracy: 0.6486\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8638 - accuracy: 0.6491 - val_loss: 0.8713 - val_accuracy: 0.6472\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8612 - accuracy: 0.6516 - val_loss: 0.8690 - val_accuracy: 0.6489\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8585 - accuracy: 0.6523 - val_loss: 0.8695 - val_accuracy: 0.6501\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8560 - accuracy: 0.6550 - val_loss: 0.8675 - val_accuracy: 0.6504\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8544 - accuracy: 0.6535 - val_loss: 0.8651 - val_accuracy: 0.6518\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8523 - accuracy: 0.6557 - val_loss: 0.8649 - val_accuracy: 0.6544\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8504 - accuracy: 0.6549 - val_loss: 0.8662 - val_accuracy: 0.6504\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8483 - accuracy: 0.6587 - val_loss: 0.8628 - val_accuracy: 0.6550\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8465 - accuracy: 0.6574 - val_loss: 0.8620 - val_accuracy: 0.6536\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8447 - accuracy: 0.6570 - val_loss: 0.8671 - val_accuracy: 0.6512\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8431 - accuracy: 0.6546 - val_loss: 0.8609 - val_accuracy: 0.6544\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8416 - accuracy: 0.6566 - val_loss: 0.8627 - val_accuracy: 0.6524\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8399 - accuracy: 0.6595 - val_loss: 0.8602 - val_accuracy: 0.6515\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8382 - accuracy: 0.6590 - val_loss: 0.8598 - val_accuracy: 0.6571\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8364 - accuracy: 0.6608 - val_loss: 0.8666 - val_accuracy: 0.6498\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8355 - accuracy: 0.6618 - val_loss: 0.8632 - val_accuracy: 0.6504\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8334 - accuracy: 0.6603 - val_loss: 0.8593 - val_accuracy: 0.6556\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8320 - accuracy: 0.6627 - val_loss: 0.8589 - val_accuracy: 0.6521\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8311 - accuracy: 0.6607 - val_loss: 0.8827 - val_accuracy: 0.6381\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8301 - accuracy: 0.6610 - val_loss: 0.8752 - val_accuracy: 0.6361\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8291 - accuracy: 0.6652 - val_loss: 0.8585 - val_accuracy: 0.6559\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8271 - accuracy: 0.6628 - val_loss: 0.8604 - val_accuracy: 0.6553\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8252 - accuracy: 0.6644 - val_loss: 0.8576 - val_accuracy: 0.6550\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8240 - accuracy: 0.6652 - val_loss: 0.8602 - val_accuracy: 0.6495\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8230 - accuracy: 0.6653 - val_loss: 0.8626 - val_accuracy: 0.6504\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8218 - accuracy: 0.6653 - val_loss: 0.8616 - val_accuracy: 0.6507\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8206 - accuracy: 0.6695 - val_loss: 0.8617 - val_accuracy: 0.6533\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8183 - accuracy: 0.6710 - val_loss: 0.8591 - val_accuracy: 0.6533\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8174 - accuracy: 0.6693 - val_loss: 0.8753 - val_accuracy: 0.6393\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8165 - accuracy: 0.6708 - val_loss: 0.8566 - val_accuracy: 0.6559\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8149 - accuracy: 0.6676 - val_loss: 0.8594 - val_accuracy: 0.6518\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8131 - accuracy: 0.6732 - val_loss: 0.8980 - val_accuracy: 0.6396\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8151 - accuracy: 0.6729 - val_loss: 0.8561 - val_accuracy: 0.6576\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8112 - accuracy: 0.6741 - val_loss: 0.8589 - val_accuracy: 0.6568\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8097 - accuracy: 0.6698 - val_loss: 0.8573 - val_accuracy: 0.6509\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8092 - accuracy: 0.6744 - val_loss: 0.8637 - val_accuracy: 0.6483\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8080 - accuracy: 0.6708 - val_loss: 0.8615 - val_accuracy: 0.6480\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8061 - accuracy: 0.6747 - val_loss: 0.8792 - val_accuracy: 0.6390\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8064 - accuracy: 0.6726 - val_loss: 0.8601 - val_accuracy: 0.6454\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8044 - accuracy: 0.6750 - val_loss: 0.8679 - val_accuracy: 0.6515\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8039 - accuracy: 0.6769 - val_loss: 0.8665 - val_accuracy: 0.6507\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8019 - accuracy: 0.6736 - val_loss: 0.8708 - val_accuracy: 0.6460\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.8007 - accuracy: 0.6778 - val_loss: 0.8699 - val_accuracy: 0.6539\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7984 - accuracy: 0.6764 - val_loss: 0.8678 - val_accuracy: 0.6498\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7983 - accuracy: 0.6794 - val_loss: 0.8685 - val_accuracy: 0.6536\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7974 - accuracy: 0.6785 - val_loss: 0.8628 - val_accuracy: 0.6495\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7959 - accuracy: 0.6765 - val_loss: 0.8574 - val_accuracy: 0.6504\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7941 - accuracy: 0.6817 - val_loss: 0.8602 - val_accuracy: 0.6504\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7933 - accuracy: 0.6832 - val_loss: 0.8674 - val_accuracy: 0.6541\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7924 - accuracy: 0.6828 - val_loss: 0.8687 - val_accuracy: 0.6489\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7911 - accuracy: 0.6820 - val_loss: 0.8659 - val_accuracy: 0.6512\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7894 - accuracy: 0.6819 - val_loss: 0.8909 - val_accuracy: 0.6460\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7908 - accuracy: 0.6807 - val_loss: 0.8670 - val_accuracy: 0.6521\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7876 - accuracy: 0.6822 - val_loss: 0.8899 - val_accuracy: 0.6448\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7875 - accuracy: 0.6813 - val_loss: 0.8615 - val_accuracy: 0.6486\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7851 - accuracy: 0.6832 - val_loss: 0.8738 - val_accuracy: 0.6434\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7849 - accuracy: 0.6855 - val_loss: 0.8586 - val_accuracy: 0.6527\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7829 - accuracy: 0.6850 - val_loss: 0.8587 - val_accuracy: 0.6541\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7807 - accuracy: 0.6864 - val_loss: 0.8638 - val_accuracy: 0.6483\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7808 - accuracy: 0.6872 - val_loss: 0.8750 - val_accuracy: 0.6457\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7802 - accuracy: 0.6860 - val_loss: 0.8687 - val_accuracy: 0.6443\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7786 - accuracy: 0.6867 - val_loss: 0.8667 - val_accuracy: 0.6501\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7767 - accuracy: 0.6903 - val_loss: 0.8834 - val_accuracy: 0.6451\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7767 - accuracy: 0.6904 - val_loss: 0.8619 - val_accuracy: 0.6512\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7745 - accuracy: 0.6877 - val_loss: 0.8762 - val_accuracy: 0.6390\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7741 - accuracy: 0.6882 - val_loss: 0.8605 - val_accuracy: 0.6454\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7723 - accuracy: 0.6889 - val_loss: 0.8658 - val_accuracy: 0.6498\n",
      "Epoch 79/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7710 - accuracy: 0.6900 - val_loss: 0.8615 - val_accuracy: 0.6521\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7698 - accuracy: 0.6912 - val_loss: 0.8671 - val_accuracy: 0.6486\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7692 - accuracy: 0.6932 - val_loss: 0.8714 - val_accuracy: 0.6437\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7685 - accuracy: 0.6886 - val_loss: 0.8944 - val_accuracy: 0.6279\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7674 - accuracy: 0.6917 - val_loss: 0.8700 - val_accuracy: 0.6536\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7653 - accuracy: 0.6943 - val_loss: 0.8979 - val_accuracy: 0.6311\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7667 - accuracy: 0.6941 - val_loss: 0.8629 - val_accuracy: 0.6515\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7642 - accuracy: 0.6933 - val_loss: 0.8620 - val_accuracy: 0.6498\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7626 - accuracy: 0.6933 - val_loss: 0.8738 - val_accuracy: 0.6501\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7609 - accuracy: 0.6950 - val_loss: 0.8709 - val_accuracy: 0.6445\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7597 - accuracy: 0.6977 - val_loss: 0.8741 - val_accuracy: 0.6504\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7587 - accuracy: 0.6949 - val_loss: 0.8699 - val_accuracy: 0.6527\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7586 - accuracy: 0.6946 - val_loss: 0.8631 - val_accuracy: 0.6480\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7551 - accuracy: 0.6983 - val_loss: 0.8788 - val_accuracy: 0.6466\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7549 - accuracy: 0.6970 - val_loss: 0.9158 - val_accuracy: 0.6114\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7570 - accuracy: 0.6959 - val_loss: 0.8796 - val_accuracy: 0.6311\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7531 - accuracy: 0.6932 - val_loss: 1.1232 - val_accuracy: 0.5805\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7594 - accuracy: 0.6943 - val_loss: 0.8819 - val_accuracy: 0.6422\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7513 - accuracy: 0.6999 - val_loss: 0.8761 - val_accuracy: 0.6515\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7508 - accuracy: 0.6971 - val_loss: 1.0622 - val_accuracy: 0.5656\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7526 - accuracy: 0.6995 - val_loss: 0.8754 - val_accuracy: 0.6466\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.6977 - val_loss: 0.8957 - val_accuracy: 0.6279\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    # batch_size = 128,\n",
    "    epochs = 100,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.815101</td>\n",
       "      <td>0.672877</td>\n",
       "      <td>0.856080</td>\n",
       "      <td>0.657642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.838199</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>0.657060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.811194</td>\n",
       "      <td>0.674139</td>\n",
       "      <td>0.858850</td>\n",
       "      <td>0.656769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.816490</td>\n",
       "      <td>0.670839</td>\n",
       "      <td>0.856630</td>\n",
       "      <td>0.655895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.829119</td>\n",
       "      <td>0.665211</td>\n",
       "      <td>0.858516</td>\n",
       "      <td>0.655895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.833417</td>\n",
       "      <td>0.660262</td>\n",
       "      <td>0.859272</td>\n",
       "      <td>0.655604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.827085</td>\n",
       "      <td>0.662785</td>\n",
       "      <td>0.860417</td>\n",
       "      <td>0.655313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.825212</td>\n",
       "      <td>0.664435</td>\n",
       "      <td>0.857581</td>\n",
       "      <td>0.655022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.848278</td>\n",
       "      <td>0.658709</td>\n",
       "      <td>0.862778</td>\n",
       "      <td>0.655022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.852309</td>\n",
       "      <td>0.655701</td>\n",
       "      <td>0.864896</td>\n",
       "      <td>0.654440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.843073</td>\n",
       "      <td>0.654634</td>\n",
       "      <td>0.860862</td>\n",
       "      <td>0.654440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.793261</td>\n",
       "      <td>0.683164</td>\n",
       "      <td>0.867425</td>\n",
       "      <td>0.654148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.782929</td>\n",
       "      <td>0.685007</td>\n",
       "      <td>0.858689</td>\n",
       "      <td>0.654148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.800698</td>\n",
       "      <td>0.677826</td>\n",
       "      <td>0.869861</td>\n",
       "      <td>0.653857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.846452</td>\n",
       "      <td>0.657448</td>\n",
       "      <td>0.862034</td>\n",
       "      <td>0.653566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.798261</td>\n",
       "      <td>0.679379</td>\n",
       "      <td>0.868531</td>\n",
       "      <td>0.653566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.767407</td>\n",
       "      <td>0.691703</td>\n",
       "      <td>0.870048</td>\n",
       "      <td>0.653566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.820584</td>\n",
       "      <td>0.669481</td>\n",
       "      <td>0.861743</td>\n",
       "      <td>0.653275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.818323</td>\n",
       "      <td>0.671034</td>\n",
       "      <td>0.859120</td>\n",
       "      <td>0.653275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.784929</td>\n",
       "      <td>0.685492</td>\n",
       "      <td>0.858579</td>\n",
       "      <td>0.652693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.758671</td>\n",
       "      <td>0.694905</td>\n",
       "      <td>0.869852</td>\n",
       "      <td>0.652693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.841631</td>\n",
       "      <td>0.656574</td>\n",
       "      <td>0.862721</td>\n",
       "      <td>0.652402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.790783</td>\n",
       "      <td>0.680737</td>\n",
       "      <td>0.867030</td>\n",
       "      <td>0.652111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.771042</td>\n",
       "      <td>0.689956</td>\n",
       "      <td>0.861455</td>\n",
       "      <td>0.652111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.832046</td>\n",
       "      <td>0.662688</td>\n",
       "      <td>0.858914</td>\n",
       "      <td>0.652111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "43  0.815101  0.672877  0.856080      0.657642\n",
       "24  0.838199  0.659000  0.859811      0.657060\n",
       "44  0.811194  0.674139  0.858850      0.656769\n",
       "40  0.816490  0.670839  0.856630      0.655895\n",
       "31  0.829119  0.665211  0.858516      0.655895\n",
       "27  0.833417  0.660262  0.859272      0.655604\n",
       "32  0.827085  0.662785  0.860417      0.655313\n",
       "33  0.825212  0.664435  0.857581      0.655022\n",
       "18  0.848278  0.658709  0.862778      0.655022\n",
       "16  0.852309  0.655701  0.864896      0.654440\n",
       "21  0.843073  0.654634  0.860862      0.654440\n",
       "59  0.793261  0.683164  0.867425      0.654148\n",
       "68  0.782929  0.685007  0.858689      0.654148\n",
       "53  0.800698  0.677826  0.869861      0.653857\n",
       "19  0.846452  0.657448  0.862034      0.653566\n",
       "55  0.798261  0.679379  0.868531      0.653566\n",
       "82  0.767407  0.691703  0.870048      0.653566\n",
       "37  0.820584  0.669481  0.861743      0.653275\n",
       "38  0.818323  0.671034  0.859120      0.653275\n",
       "67  0.784929  0.685492  0.858579      0.652693\n",
       "89  0.758671  0.694905  0.869852      0.652693\n",
       "22  0.841631  0.656574  0.862721      0.652402\n",
       "63  0.790783  0.680737  0.867030      0.652111\n",
       "78  0.771042  0.689956  0.861455      0.652111\n",
       "28  0.832046  0.662688  0.858914      0.652111"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).sort_values(by='val_accuracy', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 867us/step - loss: 0.9568 - accuracy: 0.6120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9568202495574951, 0.6120087504386902]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 637us/step\n",
      "(10305, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.835, 0.112, 0.003, 0.05 ],\n",
       "       [0.831, 0.145, 0.009, 0.015],\n",
       "       [0.081, 0.776, 0.096, 0.047],\n",
       "       ...,\n",
       "       [0.813, 0.068, 0.039, 0.08 ],\n",
       "       [0.957, 0.019, 0.001, 0.023],\n",
       "       [0.916, 0.029, 0.005, 0.05 ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_train).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rangos_precios</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11481</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10278</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18548</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15243</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18282</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10827</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18376</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16215</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9084</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18567</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3343</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18829</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9113</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17737</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12364</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12682</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11433</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9068</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rangos_precios  preds\n",
       "11481             3.0      0\n",
       "9687              0.0      0\n",
       "2764              0.0      1\n",
       "2285              2.0      0\n",
       "1030              1.0      0\n",
       "10278             1.0      1\n",
       "6533              0.0      0\n",
       "18548             0.0      0\n",
       "10107             0.0      0\n",
       "15243             1.0      1\n",
       "3187              1.0      1\n",
       "7372              0.0      1\n",
       "5028              3.0      1\n",
       "18282             2.0      1\n",
       "634               1.0      1\n",
       "492               1.0      0\n",
       "5114              0.0      0\n",
       "6484              0.0      0\n",
       "3530              1.0      1\n",
       "3772              1.0      3\n",
       "841               1.0      0\n",
       "10675             0.0      1\n",
       "583               1.0      1\n",
       "10121             1.0      0\n",
       "10827             1.0      3\n",
       "18376             0.0      0\n",
       "6203              2.0      1\n",
       "16215             1.0      1\n",
       "3748              3.0      3\n",
       "5546              2.0      1\n",
       "5057              3.0      3\n",
       "9084              1.0      0\n",
       "1425              1.0      1\n",
       "3790              0.0      0\n",
       "18567             0.0      0\n",
       "3343              3.0      3\n",
       "24                1.0      0\n",
       "18829             1.0      1\n",
       "3650              1.0      0\n",
       "4345              3.0      1\n",
       "9113              1.0      1\n",
       "4998              0.0      0\n",
       "17737             3.0      0\n",
       "4280              3.0      3\n",
       "7515              0.0      0\n",
       "12364             2.0      3\n",
       "7171              0.0      0\n",
       "12682             0.0      0\n",
       "11433             1.0      3\n",
       "9068              1.0      1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_preds = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    # print(predictions_tot[i].argmax())\n",
    "    list_preds.append(predictions[i].argmax())\n",
    "\n",
    "df_preds = pd.DataFrame(y_train)\n",
    "df_preds['preds'] = list_preds\n",
    "df_preds.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model_12_09_20_03.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model_12_09_20_03.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Data scaled\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8646288209606987\n",
      "0.6839519650655022\n",
      "Accuracy: 0.6839519650655022\n",
      "Recall: 0.6839519650655022\n",
      "Precision: 0.6839519650655022\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Modelo 1 - XGBClassifier\n",
    "modelo = XGBClassifier(\n",
    "    # max_depth=6, \n",
    "    # learning_rate=0.08\n",
    "    )\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "preds = modelo.predict(X_test)\n",
    "\n",
    "print(modelo.score(X_train, y_train))\n",
    "print(modelo.score(X_test, y_test))\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, preds))\n",
    "print('Recall:', recall_score(y_test, preds, average='micro'))\n",
    "print('Precision:', precision_score(y_test, preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6824964894875977\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=70, n_jobs=0,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=0, reg_alpha=0, ...)\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "#XGBoost\n",
    "params = {\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'n_estimators': [50, 60, 70, 80],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "xgrid = GridSearchCV(estimator=xgb.XGBClassifier(),           \n",
    "                      param_grid=params, \n",
    "                      cv=10,\n",
    "                      verbose=0) \n",
    "                      \n",
    "xgrid.fit(X_train, y_train)\n",
    "\n",
    "print(xgrid.best_score_)\n",
    "print(xgrid.best_estimator_)\n",
    "print(xgrid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'holi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18384\\814774234.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mholi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'holi' is not defined"
     ]
    }
   ],
   "source": [
    "holi.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8646288209606987\n",
      "0.6839519650655022\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8944\\4186856655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Recall:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'micro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'micro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pieci\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pieci\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     93\u001b[0m         raise ValueError(\n\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             )\n\u001b[0;32m     97\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "# PROBAMOS CON UN MODELO B√ÅSICO DE REGRESI√ìN LINEAL -> MALOS RESULTADOS EN TRAIN Y TEST\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "preds = lm.predict(X_test)\n",
    "preds\n",
    "\n",
    "print(modelo.score(X_train, y_train))\n",
    "print(modelo.score(X_test, y_test))\n",
    "\n",
    "# print('Accuracy:', accuracy_score(y_test, preds))\n",
    "# print('Recall:', recall_score(y_test, preds, average='micro'))\n",
    "# print('Precision:', precision_score(y_test, preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 29 features, but LinearRegression is expecting 465 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8944\\3685719658.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpol_reg_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoly_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpol_reg_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpol_reg_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pieci\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pieci\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \"\"\"\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pieci\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pieci\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pieci\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             raise ValueError(\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 29 features, but LinearRegression is expecting 465 features as input."
     ]
    }
   ],
   "source": [
    "# PROBAMOS CON UN MODELO DE REGRESI√ìN POLIN√ìMICA DE GRADO 2 -> MALOS RESULTADOS EN TRAIN Y TEST\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "poly_reg.fit(X_train)\n",
    "X_poly_train = poly_reg.transform(X_train)  \n",
    "\n",
    "pol_reg_2 = LinearRegression()\n",
    "pol_reg_2.fit(X_poly_train, y_train)\n",
    "\n",
    "predictions = pol_reg_2.predict(poly_reg.transform(X_test))\n",
    "\n",
    "print(pol_reg_2.score(X_train, y_train))\n",
    "print(pol_reg_2.score(X_test, y_test))\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print('Recall:', recall_score(y_test, predictions, average='micro'))\n",
    "print('Precision:', precision_score(y_test, predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier \n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator=RandomForestClassifier(),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    "\n",
    "#Train the classifier.\n",
    "bbc.fit(X_train, y_train)\n",
    "pred_y = bbc.predict(X_test)\n",
    "mostrar_resultados(y_test, pred_y)\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "7\n",
    "8\n",
    "9\n",
    "bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    " \n",
    "#Train the classifier.\n",
    "bbc.fit(X_train, y_train)\n",
    "pred_y = bbc.predict(X_test)\n",
    "mostrar_resultados(y_test, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.651611729444436\n",
      "0.8240830101261405\n",
      "0.7455660347996529\n"
     ]
    }
   ],
   "source": [
    "# PROBAMOS CON UN MODELO DE REGRESI√ìN POLIN√ìMICA DE GRADO 3 -> NO FUNCIONA!\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree=3)\n",
    "poly_reg.fit(X_train)\n",
    "X_poly_train = poly_reg.transform(X_train)  \n",
    "\n",
    "pol_reg_2 = LinearRegression()\n",
    "pol_reg_2.fit(X_poly_train, y_train)\n",
    "\n",
    "predictions = pol_reg_2.predict(poly_reg.transform(X_test))\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print(pol_reg_2.score(X_poly_train, y_train))\n",
    "print(pol_reg_2.score(poly_reg.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.5955240174672489\n",
      "1.0\n",
      "0.036680226738844524\n"
     ]
    }
   ],
   "source": [
    "# VAMOS A PROBAR CON UN ARBOL DE DECISION SENCILLO -> MUY BUENOS RESULTADOS EN TRAIN, MUY MALOS EN TEST\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtr.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "print('MAE', mean_absolute_error(y_test, y_pred))\n",
    "print(dtr.score(X_train, y_train))\n",
    "print(dtr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(50,30))\n",
    "\n",
    "# plot_tree(dtr, feature_names=X_train.columns, class_names='actual', fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748445437570075\n",
      "0.8142529142982222\n",
      "MAE: 3.574236456063907\n"
     ]
    }
   ],
   "source": [
    "# PROBAMOS UN RANDOM FOREST. FUNCIONA BASTANTE BIEN Y MEJORAMOS MAE.\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "rnd_reg = RandomForestRegressor(n_estimators=450,\n",
    "                                 random_state=42)\n",
    "rnd_reg.fit(X_train, y_train)\n",
    "\n",
    "print(rnd_reg.score(X_train, y_train))\n",
    "print(rnd_reg.score(X_test, y_test))\n",
    "\n",
    "predictions_rf = rnd_reg.predict(X_test)\n",
    "# predictions_rf = np.exp(rnd_reg.predict(X_test))\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test, predictions_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.318972331180349\n",
      "0.7660050342581729\n",
      "0.7634373150293416\n"
     ]
    }
   ],
   "source": [
    "# PROBAMOS ADABOOST. EMPEORA EN TODOS LOS ASPECTOS\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada_reg = AdaBoostRegressor(n_estimators=200,\n",
    "                            random_state=42)\n",
    "ada_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ada_reg = ada_reg.predict(X_test)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred_ada_reg))\n",
    "print(ada_reg.score(X_train, y_train))\n",
    "print(ada_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.3696823226529835\n",
      "0.7690442854900079\n",
      "0.7658233868175994\n"
     ]
    }
   ],
   "source": [
    "# PROBAMOS GRADIENT BOOSTING. MALOS RESULTADOS\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2,\n",
    "                                 n_estimators=3,\n",
    "                                 learning_rate=1.0,\n",
    "                                 random_state=42)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_gbrt = gbrt.predict(X_test)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred_gbrt))\n",
    "print(gbrt.score(X_train, y_train))\n",
    "print(gbrt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCALAMOS LOS DATOS PARA PROBAR DE NUEVO GRADIENT BOOSTING. LOS RESULTADOS NO MEJORAN EN NINGUN CASO.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scal = scaler.fit_transform(X_train)  # Valor m√≠nimo 10 --> 0, Valor m√°ximo 50 --> 1\n",
    "X_test_scal = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.3696823226529835\n",
      "0.7690442854900079\n",
      "0.7658233868175994\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2,\n",
    "                                 n_estimators=3,\n",
    "                                 learning_rate=1.0,\n",
    "                                 random_state=42)\n",
    "gbrt.fit(X_train_scal, y_train)\n",
    "\n",
    "\n",
    "y_pred_gbrt = gbrt.predict(X_test_scal)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred_gbrt))\n",
    "print(gbrt.score(X_train_scal, y_train))\n",
    "print(gbrt.score(X_test_scal, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.969207647236344\n",
      "0.9036892172753273\n",
      "0.8048048392057872\n"
     ]
    }
   ],
   "source": [
    "# CON XGBOOST TAMBI√âN TENEMOS MEJORES RESULTADOS. VAMOS A SEGUIR TRABAJANDO CON RANDOM FOREST Y XGBOOST PARA VER CU√ÅL LLEGA A RESULTADOS MEJORES.\n",
    "\n",
    "import xgboost\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor(random_state=42,\n",
    "                            )\n",
    "\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print(xgb_reg.score(X_train, y_train))\n",
    "print(xgb_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.9666787078957153\n",
      "0.9036892172753273\n",
      "0.8049315526394905\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor(random_state=42\n",
    "                               )\n",
    "\n",
    "xgb_reg.fit(X_train_scal, y_train)\n",
    "\n",
    "y_pred = xgb_reg.predict(X_test_scal)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print(xgb_reg.score(X_train_scal, y_train))\n",
    "print(xgb_reg.score(X_test_scal, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAMOS A HACER UNA PRUEBA CON REGRESION POL Y LASSOCV - NO ES √öTIL\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "\n",
    "# p = PolynomialFeatures()\n",
    "\n",
    "# features_poly = p.fit_transform(X)\n",
    "\n",
    "# poly_df = pd.DataFrame(features_poly, columns=p.get_feature_names_out())\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(poly_df, y, random_state=28)\n",
    "\n",
    "# ss = StandardScaler()\n",
    "# ss.fit(X_train)\n",
    "# X_train_sc = ss.transform(X_train)\n",
    "# X_test_sc = ss.transform(X_test)\n",
    "\n",
    "# y_train_log = np.log(y_train)\n",
    "# y_test_log = np.log(y_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# lasso = LassoCV()\n",
    "\n",
    "\n",
    "# lr.fit(X_train_sc, y_train_log)\n",
    "# lasso.fit(X_train_sc, y_train_log)\n",
    "\n",
    "# print(lr.score(X_train_sc, y_train_log))\n",
    "# print(lr.score(X_test_sc, y_test_log))\n",
    "\n",
    "# y_pred = np.exp(lasso.predict(X_test_sc))\n",
    "# print('MAE:', mean_absolute_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bed665d392a0b16c59368a0492a31cfeef380a776e0741f5d7e9c0d91554052a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
